{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population estimation\n",
    "\n",
    "1. Data acqisition\n",
    "   1. Download world pop 100 m with year data same as event\n",
    "   2. Download event data from ESA\n",
    "   3. Download OSM boundaries for aois (admin level 4 (world 1, turkey 2, regions 3, subregions 4))\n",
    "2. Preprocessing\n",
    "   1. Extract aoi and builtUp files from zips according to the scripts below\n",
    "   2. Cleanup builtUp: point on surface where the features are polygons\n",
    "   3. Merge aoi files to one layer\n",
    "   4. Merge builtUp files to one layer\n",
    "   5. Dissolve aois\n",
    "   6. Clip OSM boundaries to admin zones only containing the aois\n",
    "3. *Calculation*: total population\n",
    "   1. Clip pop raster with aoi_diss and warp to EPSG:3857\n",
    "   2. Zonal Statistics: calculate sum for aois \n",
    "   3. Statistics by category: sum aoi sums by using column esmr_id -> `pop_total`\n",
    "4. *Calculation*: population per admin\n",
    "   1. Join OSM boundaries to aois\n",
    "   2. Zonal statistics: calculate sum for aois\n",
    "   3. Statistics by category: sum by using name of admin zones -> `pop_per_admin`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre (1 day before)/Post (4 weeks after)\n",
    "\n",
    "1. Preprocessing OSM buildings data\n",
    "   1. Download OSM data according to the script below (pre/post)\n",
    "   2. Calculate point on surface for osm polygon layer\n",
    "   3. Merge new layer with osm point layer and reproject to EPSG:3857 -> `osm_centroids`\n",
    "2. Pop per residential building (per cell for higher accuracy)\n",
    "   1. Create grid in EPSG:3857 with 1 kmÂ² cell size (extent from aois)\n",
    "   2. Cleanup pts (only residential)\n",
    "   3. Count points in polygon (osm/pts in grid)\n",
    "   4. Join pts_count and osm_count\n",
    "   5. Delete cells where both counts are 0 (osm is 0 and pts is 0) -> `count per cell`\n",
    "   6. Zonal statistics: calculate pop sum per cell (osm/pts count layers)\n",
    "   7. Calculate pop sum / count -> `pop per building per cell`\n",
    "3. Pop per residential building (per admin for comparison)\n",
    "   1. Dissolve aois_admin\n",
    "   2. Count points in polygon (osm/pts in aoi_admin_3857) -> `count_per_admin`\n",
    "   3. Zonal statistics: calculate pop sum per admin\n",
    "   4. Calculate pop sum / count -> `pop per building per admin`\n",
    "4. *Analysis*: Completeness\n",
    "   1. Calculate difference (osm count - pts count)\n",
    "   2. Calculate deviation (osm count - pts count) / osm count * 100\n",
    "   3. Assign classes: CASE WHEN \"deviation\" > 1 THEN 2 WHEN \"deviation\" < -1 THEN 0 ELSE 1 END\n",
    "   4. Handle NULL values (if osm_count 0 and pts_count > 0 THEN class = 0)\n",
    "   5. Generate class names: CASE WHEN \"class\" is 0 THEN 'less osm' WHEN \"class\" is 1 THEN 'similar' WHEN \"class\" is 2 THEN 'more osm' END -> `completeness`\n",
    "   6. Statistics by categories: cell count for each class -> `cell_statistics`\n",
    "   7. Visualize layers from before in map (left pre/right post)\n",
    "\n",
    "HERE\n",
    "1. *Discussion*: after the event much more OSM data (currentness)\n",
    "   1. In osm_counts, assign timestamp (pre/post)\n",
    "   2. Join both osm_counts (pre/post)\n",
    "   3. Calculate difference (post - pre)\n",
    "   4. Calculate deviation (post- pre) / post * 100 -> `currentness_osm`\n",
    "   5. Visualize deviation: negative (one colour) and less to more change with continuous scale\n",
    "2. *Discussion*: if aoi prone to disasters -> already more OSM data \n",
    "   1. Compare ohsome figures\n",
    "\n",
    "*Attention: Aois in Indonesia not unique, so buffer before dissolving (0,0005 degrees) and adding unique id field after intersecting aois with osm boundaries necessary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Extracting files for Indonesia\"\"\"\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "print(\"Extracting data...\")\n",
    "\n",
    "in_dir = f\"../data/ind/extract/\"\n",
    "for item in glob(in_dir + \"*\"):\n",
    "    if item not in glob(in_dir + \"*area_of_interest*\") and item not in glob(in_dir + \"*built_up*\"):\n",
    "        os.remove(item)\n",
    "    if item in glob(in_dir + \"*.kmz\"):\n",
    "        os.remove(item)\n",
    "\n",
    "print(\"...finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Extracting files for Turkiye\"\"\"\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "print(\"Extracting data...\")\n",
    "\n",
    "in_dir = f\"../data/tur/extract/\"\n",
    "for item in glob(in_dir + \"*\"):\n",
    "    if item not in glob(in_dir + \"*areaOfInterest*\") and item not in glob(in_dir + \"*builtUp*\"):\n",
    "        os.remove(item)\n",
    "    if item in glob(in_dir + \"*.kmz\") or item in glob(in_dir + \"*.xml\"):\n",
    "        os.remove(item)\n",
    "\n",
    "print(\"...finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Download OSM data\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from ohsome import OhsomeClient\n",
    "\n",
    "\n",
    "client = OhsomeClient()\n",
    "filter_buildings = \"building in (yes, house, residential, appartements)\"\n",
    "country_list = [\"ind\", \"tur\"]\n",
    "\n",
    "for country in country_list:\n",
    "\n",
    "    in_dir = Path(f\"../data/{country}\")\n",
    "\n",
    "    bpolys = gpd.read_file(in_dir / \"mapdata.gpkg\", layer = \"aoi_diss\")\n",
    "\n",
    "    # specify timestamp as 1 day before event and 4 weeks afterwards\n",
    "    if country == \"ind\":\n",
    "        time_list = [\"2018-09-27\", \"2018-10-25\"]\n",
    "    elif country == \"tur\":\n",
    "        time_list = [\"2023-02-05\", \"2023-03-05\"]\n",
    "\n",
    "    try:\n",
    "        for time_c in time_list:\n",
    "            response = client.elements.geometry.post(\n",
    "                bpolys = bpolys, \n",
    "                filter = filter_buildings,\n",
    "                time = time_c,\n",
    "                properties = \"metadata\"\n",
    "            )\n",
    "            results_df = response.as_dataframe()\n",
    "            results_df.to_file(in_dir / f\"osm_{time_c}_buildings.geojson\", driver = \"GeoJSON\")\n",
    "    except Exception as err:\n",
    "        print(f\"Could not send request to ohsome API: {err}\")\n",
    "        sys.exit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 ('geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef1779f0ff1eaf3734d7b74179417e75fee630c863368bd74cbaec57a92c71fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
